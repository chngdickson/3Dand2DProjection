{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from open3d.visualization import rendering\n",
    "# Util function for loading point clouds|\n",
    "from proj_pcd2img import project_3d_to_2d\n",
    "from segment3dwithAnno import segment3D_with2DAnno, segment3D_With2DMask, create_2d_mask\n",
    "\n",
    "# Utils for mesh reconstruction\n",
    "from alphashape import alphashape\n",
    "import trimesh\n",
    "import pymeshfix\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paint_color(pcd, color:str):\n",
    "    if color ==\"red\":\n",
    "        color_code = [1,0,0]\n",
    "    elif color ==\"green\":\n",
    "        color_code = [0,1,0]\n",
    "    elif color ==\"blue\":\n",
    "        color_code = [0,0,1]\n",
    "    elif color == \"grey\":\n",
    "        color_code = [0.9, 0.9, 0.9]\n",
    "    else:\n",
    "        color_code = [0,0,0]\n",
    "    return pcd.paint_uniform_color(np.array(color_code))\n",
    "\n",
    "def create_two_color_mask(rgb_image):\n",
    "    \"\"\"\n",
    "    Create a binary mask for an RGB image with exactly two colors: black and another uniform color.\n",
    "    \n",
    "    Args:\n",
    "        rgb_image: (H, W, 3) RGB image with only two colors (black + one uniform color).\n",
    "    \n",
    "    Returns:\n",
    "        mask: (H, W) binary mask (True for uniform color, False for black).\n",
    "    \"\"\"\n",
    "    # Find the non-black color (assuming it's uniform)\n",
    "    non_black_pixels = rgb_image[np.any(rgb_image != [255, 255, 255], axis=-1)]\n",
    "    if len(non_black_pixels) == 0:\n",
    "        return np.zeros_like(rgb_image[:, :, 0], dtype=bool)  # All black\n",
    "    \n",
    "    # Get the unique non-black color (should be just one)\n",
    "    uniform_color = non_black_pixels[0]\n",
    "    \n",
    "    # Create mask: True where pixel matches the uniform color\n",
    "    mask = np.all(rgb_image == uniform_color, axis=-1)\n",
    "    return mask\n",
    "\n",
    "def o3dpcd2img(pcd, width, height, return_camera=False):\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window(width=width, height=height, visible=False)\n",
    "    vis.get_render_option().point_size = 2\n",
    "    vis.add_geometry(pcd)\n",
    "    view_ctl = vis.get_view_control()\n",
    "    view_ctl.set_zoom(0.6)\n",
    "    view_ctl.set_lookat(pcd.get_center())\n",
    "    view_ctl.set_up((1, 0, 0))  # set the positive direction of the x-axis as the up direction\n",
    "    view_ctl.set_front((0, 0, 1))  # set the positive direction of the x-axis toward you\n",
    "    vis.update_renderer()\n",
    "    img = np.array(vis.capture_screen_float_buffer(True))\n",
    "    depth = np.array(vis.capture_depth_float_buffer(True))\n",
    "    mask = create_two_color_mask(img)\n",
    "    if return_camera:\n",
    "       # https://www.open3d.org/html/python_api/open3d.camera.PinholeCameraIntrinsic.html\n",
    "       cam = view_ctl.convert_to_pinhole_camera_parameters()\n",
    "       return img, depth, mask, cam.intrinsic.intrinsic_matrix, cam.extrinsic\n",
    "    vis.destroy_window()\n",
    "    return img, depth, mask\n",
    "\n",
    "\n",
    "\n",
    "def pcd_2_mesh(pcd):\n",
    "    alpha = 0.5\n",
    "    mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(pcd, alpha)\n",
    "    mesh.compute_vertex_normals()\n",
    "    return mesh\n",
    "def rasterize_with_zbuffer(points_3d, H,W):\n",
    "    \"\"\"\n",
    "    Rasterizes 3D points with z-buffering (keeps closest points).\n",
    "    \n",
    "    Args:\n",
    "        points_3d: (N, 3) tensor of 3D points (x, y, z)\n",
    "        image_size: (height, width) of output image\n",
    "    \n",
    "    Returns:\n",
    "        image: (H, W) binary mask (1 if pixel has a point, else 0)\n",
    "        depth_buffer: (H, W) depth map (smallest z per pixel)\n",
    "    \"\"\"\n",
    "\n",
    "    device = points_3d.device\n",
    "    \n",
    "    # Normalize x, y to [0, 1], keep z for depth\n",
    "    xy_min = points_3d[:, :2].min(dim=0)[0]\n",
    "    xy_max = points_3d[:, :2].max(dim=0)[0]\n",
    "    xy_normalized = (points_3d[:, :2] - xy_min) / (xy_max - xy_min + 1e-6)\n",
    "    \n",
    "    # Scale to image dimensions\n",
    "    u = (xy_normalized[:, 0] * (W - 1)).long()  # [0, W-1]\n",
    "    v = (xy_normalized[:, 1] * (H - 1)).long()  # [0, H-1]\n",
    "    z = points_3d[:, 2]  # Depth values\n",
    "    \n",
    "    # Initialize buffers\n",
    "    image = torch.zeros((H, W), device=device)\n",
    "    depth_buffer = torch.full((H, W), float('inf'), device=device)\n",
    "    \n",
    "    # Z-buffering\n",
    "    for ui, vi, zi in zip(u, v, z):\n",
    "        if zi < depth_buffer[vi, ui]:\n",
    "            depth_buffer[vi, ui] = zi\n",
    "            image[vi, ui] = 1  # Mark occupied pixel\n",
    "    \n",
    "    return image, depth_buffer\n",
    "\n",
    "import torch\n",
    "\n",
    "def rasterize_with_priority(points_3d, image_size:tuple, axis='xy', highest = True):\n",
    "    \"\"\"\n",
    "    Rasterizes 3D points with priority (highest/lowest first).\n",
    "    \n",
    "    Args:\n",
    "        points_3d: (N, 3) or (B, N, 3) tensor of 3D points.\n",
    "        image_size: (H, W) output dimensions.\n",
    "        axis: \n",
    "            - 'xy' (top-down view, Z for depth)\n",
    "            - 'xz' (front view, Y for depth)\n",
    "            - 'yz' (side view, X for depth)\n",
    "        priority:\n",
    "            - 'highest': Points with largest depth are drawn first.\n",
    "            - 'lowest': Points with smallest depth are drawn first.\n",
    "    \n",
    "    Returns:\n",
    "        image: (H, W) or (B, H, W) binary mask.\n",
    "        depth_buffer: (H, W) or (B, H, W) depth map.\n",
    "    \"\"\"\n",
    "    H, W = image_size\n",
    "    device = points_3d.device\n",
    "    batched = points_3d.dim() == 3\n",
    "    points_3d[...,2]*=-1\n",
    "    # Select axes for projection and depth\n",
    "    if axis == 'xy':\n",
    "        proj_coords = points_3d[..., :2]  # (N, 2) or (B, N, 2)\n",
    "        depth = points_3d[..., 2]         # (N,) or (B, N)\n",
    "    elif axis == 'xz':\n",
    "        proj_coords = points_3d[..., [0, 2]]\n",
    "        depth = points_3d[..., 1]\n",
    "    elif axis == 'yz':\n",
    "        proj_coords = points_3d[..., [1, 2]]\n",
    "        depth = points_3d[..., 0]\n",
    "    else:\n",
    "        raise ValueError(\"axis must be 'xy', 'xz', or 'yz'\")\n",
    "\n",
    "    # Normalize projected coordinates to [0, 1]\n",
    "    proj_min = proj_coords.amin(dim=-2, keepdim=True)  # (1, 2) or (B, 1, 2)\n",
    "    proj_max = proj_coords.amax(dim=-2, keepdim=True)\n",
    "    proj_normalized = (proj_coords - proj_min) / (proj_max - proj_min + 1e-6)\n",
    "\n",
    "    # Scale to image dimensions\n",
    "    u = (proj_normalized[..., 0] * (W - 1)).long()  # (N,) or (B, N)\n",
    "    v = (proj_normalized[..., 1] * (H - 1)).long()\n",
    "\n",
    "    # Sort points by depth (highest or lowest first)\n",
    "    if highest:\n",
    "        sort_idx = torch.argsort(depth, descending=True)  # Draw farthest first\n",
    "    else:\n",
    "        sort_idx = torch.argsort(depth, descending=False) # Draw closest first\n",
    "\n",
    "    if batched:\n",
    "        # Batched sorting (B, N)\n",
    "        u = torch.gather(u, 1, sort_idx)\n",
    "        v = torch.gather(v, 1, sort_idx)\n",
    "        depth = torch.gather(depth, 1, sort_idx)\n",
    "    else:\n",
    "        # Single point cloud sorting\n",
    "        u = u[sort_idx]\n",
    "        v = v[sort_idx]\n",
    "        depth = depth[sort_idx]\n",
    "\n",
    "    # Initialize output\n",
    "    if batched:\n",
    "        B = points_3d.shape[0]\n",
    "        image = torch.zeros((B, H, W), device=device)\n",
    "        depth_buffer = torch.full((B, H, W), float('inf'), device=device)\n",
    "    else:\n",
    "        image = torch.zeros((H, W), device=device)\n",
    "        depth_buffer = torch.full((H, W), float('inf'), device=device)\n",
    "\n",
    "    # Rasterize in sorted order\n",
    "    if batched:\n",
    "        for b in range(B):\n",
    "            for ui, vi, zi in zip(u[b], v[b], depth[b]):\n",
    "                if zi < depth_buffer[b, vi, ui]:  # Overwrite if closer (or farther)\n",
    "                    depth_buffer[b, vi, ui] = zi\n",
    "                    image[b, vi, ui] = 1\n",
    "    else:\n",
    "        for ui, vi, zi in zip(u, v, depth):\n",
    "            if zi < depth_buffer[vi, ui]:\n",
    "                depth_buffer[vi, ui] = zi\n",
    "                image[vi, ui] = 1\n",
    "\n",
    "    return image, depth_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.io.read_point_cloud(\"multi_tree.ply\")\n",
    "# pcd_color = paint_color(pcd, \"grey\")\n",
    "\n",
    "width, height = (640, 480)\n",
    "img, depth, mask_2d = o3dpcd2img(pcd, width=width, height=height)\n",
    "img, depth, mask_2d, intrins, extrinsic = o3dpcd2img(pcd, width=width, height=height, return_camera=True)\n",
    "\n",
    "\n",
    "pcd_selected, mask_2d = segment3D_With2DMask(pcd, mask_2d, intrins, extrinsic)\n",
    "\n",
    "\n",
    "\n",
    "# print(np.array(pcd_selected.points).shape)\n",
    "# plt.imshow(mask_2d.detach().cpu().numpy())\n",
    "# plt.show()\n",
    "# pcd_selected = segment3D_with2DAnno(pcd_color, segment2d_anno, 480, 640, intrins, extrinsic)\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def rasterize_3dto2D_numpyv3(\n",
    "    pointcloud, \n",
    "    mask_2d=None, \n",
    "    img_shape=None,\n",
    "    min_xyz=None,  \n",
    "    max_xyz=None,  \n",
    "    axis='z', \n",
    "    highest_first=True,  # Keep highest points in rasterization\n",
    "    depth_weighting=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Rasterizes a point cloud into a 2D image, keeping only the highest points per pixel,\n",
    "    and filters the point cloud based on the provided mask.\n",
    "    \n",
    "    Returns:\n",
    "        filtered_pointcloud: Points inside the mask (not necessarily highest per pixel).\n",
    "        raster_image: 2D image with only highest points per pixel.\n",
    "        raster_filtered_img: Same as raster_image (for compatibility).\n",
    "    \"\"\"\n",
    "    # --- Input checks ---\n",
    "    if mask_2d is None and img_shape is None:\n",
    "        raise ValueError(\"mask_2d or img_shape must be provided.\")\n",
    "    H, W = mask_2d.shape if mask_2d is not None else img_shape\n",
    "    if mask_2d is None:\n",
    "        mask_2d = np.ones((H, W), dtype=bool)\n",
    "\n",
    "    # --- Extract depth ---\n",
    "    depth = pointcloud[:, {'x': 0, 'y': 1, 'z': 2}[axis]]\n",
    "    norm_depth = (depth - depth.min()) / (depth.max() - depth.min() + 1e-6)\n",
    "    if highest_first:\n",
    "        norm_depth = 1.0 - norm_depth  # Highest depth = 1 (red)\n",
    "\n",
    "    # --- Custom colormap (Red=high, Blue=mid, Green=low) ---\n",
    "    cmap = plt.get_cmap('gist_rainbow')\n",
    "\n",
    "    # --- Project to 2D ---\n",
    "    if axis == 'z':\n",
    "        coords = pointcloud[:, :2]  # XY projection\n",
    "    elif axis == 'y':\n",
    "        coords = pointcloud[:, [0, 2]]  # XZ projection\n",
    "        coords[:, 1] *= -1\n",
    "    elif axis == 'x':\n",
    "        coords = pointcloud[:, [1, 2]]  # YZ projection\n",
    "        coords[:, 1] *= -1\n",
    "\n",
    "    # Normalize coordinates to [0, 1]\n",
    "    min_coord = np.array([min_xyz[0], min_xyz[1]]) if min_xyz is not None else coords.min(axis=0)\n",
    "    max_coord = np.array([max_xyz[0], max_xyz[1]]) if max_xyz is not None else coords.max(axis=0)\n",
    "    coords_normalized = (coords - min_coord) / (max_coord - min_coord + 1e-6)\n",
    "    \n",
    "    # Convert to pixel indices\n",
    "    u = (coords_normalized[:, 0] * (W - 1)).astype(int)\n",
    "    v = (coords_normalized[:, 1] * (H - 1)).astype(int)\n",
    "\n",
    "    # --- Filter points based on mask ---\n",
    "    valid_mask = (u >= 0) & (u < W) & (v >= 0) & (v < H) & mask_2d[v, u]\n",
    "    filtered_pointcloud = pointcloud[valid_mask]\n",
    "    u_valid, v_valid = u[valid_mask], v[valid_mask]\n",
    "    norm_depth_valid = norm_depth[valid_mask]\n",
    "\n",
    "    # --- Rasterize: Keep only the highest point in each pixel ---\n",
    "    raster_image = np.zeros((H, W, 3), dtype=np.float32)\n",
    "    depth_buffer = np.full((H, W), -np.inf)  # Track highest depth per pixel\n",
    "\n",
    "    # Sort points by depth (highest first)\n",
    "    sorted_order = np.argsort(norm_depth_valid)[::-1]\n",
    "    u_sorted = u_valid[sorted_order]\n",
    "    v_sorted = v_valid[sorted_order]\n",
    "    norm_depth_sorted = norm_depth_valid[sorted_order]\n",
    "\n",
    "    # Assign colors to the highest point in each pixel\n",
    "    for i in range(len(u_sorted)):\n",
    "        u_pix, v_pix = u_sorted[i], v_sorted[i]\n",
    "        if norm_depth_sorted[i] > depth_buffer[v_pix, u_pix]:\n",
    "            depth_buffer[v_pix, u_pix] = norm_depth_sorted[i]\n",
    "            raster_image[v_pix, u_pix] = cmap(norm_depth_sorted[i])[:3]  # RGB only\n",
    "\n",
    "    return filtered_pointcloud, raster_image, raster_image.copy()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def torch_lexsort(a, dim=-1):\n",
    "    assert dim == -1  # Transpose if you want differently\n",
    "    assert a.ndim == 2  # Not sure what is numpy behaviour with > 2 dim\n",
    "    # To be consistent with numpy, we flip the keys (sort by last row first)\n",
    "    a_unq, inv = torch.unique(a.flip(0), dim=dim, sorted=True, return_inverse=True)\n",
    "    return torch.argsort(inv)\n",
    "\n",
    "def rasterize_3dto2D_torch(\n",
    "    pointcloud, \n",
    "    mask_2d: np.ndarray=None, \n",
    "    img_shape: tuple=None,\n",
    "    min_xyz: tuple=None,  # (min_x, min_y, min_z)\n",
    "    max_xyz: tuple=None,  # (max_x, max_y, max_z)\n",
    "    axis='z', \n",
    "    highest_first=True,\n",
    "    depth_weighting=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Rasterize point cloud with explicit bounds and depth-based weighting.\n",
    "    Higher values → Red\n",
    "    Mid values → Blue\n",
    "    Lowest values → Green\n",
    "    \n",
    "    Args:\n",
    "        pointcloud: (N, 3) array of 3D points.\n",
    "        mask_2d: (H, W) binary mask (True = keep point).\n",
    "        img_shape: (H, W) if mask_2d is not None.\n",
    "        min_xyz: Tuple of (min_x, min_y, min_z) bounds.\n",
    "        max_xyz: Tuple of (max_x, max_y, max_z) bounds.\n",
    "        axis: 'xy', 'xz', or 'yz' (projection plane).\n",
    "        highest_first: If True, prioritize farthest points; else closest.\n",
    "        depth_weighting: If True, farther points have lower values.\n",
    "    \n",
    "    Returns:\n",
    "        filtered_pointcloud: (M, 3) array (M <= N).\n",
    "        raster_image: (H, W) binary | (H, W, 3) RGB image (Red=High, Blue=Mid, Green=Low).\n",
    "        raster_filtered_img: (H, W) binary of masked points | (H, W, 3) RGB image of masked points.\n",
    "    \"\"\"\n",
    "    assert not(mask_2d is None and img_shape is None), \"mask_2d or img_shape must be present for rasterization\"\n",
    "    device = pointcloud.device\n",
    "    dtype = pointcloud.dtype\n",
    "    if mask_2d is not None:\n",
    "        H, W = mask_2d.shape\n",
    "        if isinstance(mask_2d,np.ndarray):\n",
    "            mask_2d = torch.tensor(mask_2d, dtype=torch.bool, device=device)\n",
    "    else:\n",
    "        H, W = img_shape\n",
    "    \n",
    "    xyz = pointcloud[:,:3]\n",
    "    if axis == 'z':\n",
    "        depth = pointcloud[:, 2]  # Z-axis for XY projection\n",
    "        coords = xyz[:, :2]\n",
    "        min_coord = torch.tensor([min_xyz[0], min_xyz[1]]) if min_xyz is not None else coords.min(dim=0)[0]\n",
    "        max_coord = torch.tensor([max_xyz[0], max_xyz[1]]) if max_xyz is not None else coords.max(dim=0)[0]\n",
    "    elif axis == 'y':\n",
    "        depth = pointcloud[:, 1]  # Y-axis for XZ projection\n",
    "        coords[:,1] = coords[:,1] * -1\n",
    "        min_coord = torch.tensor([min_xyz[0], min_xyz[2]]) if min_xyz is not None else coords.min(dim=0)[0]\n",
    "        max_coord = torch.tensor([max_xyz[0], max_xyz[2]]) if max_xyz is not None else coords.max(dim=0)[0]\n",
    "    elif axis == 'x':\n",
    "        depth = pointcloud[:, 0]  # X-axis for YZ projection\n",
    "        coords[:,1] = coords[:,1] * -1\n",
    "        min_coord = torch.tensor([min_xyz[1], min_xyz[2]]) if min_xyz is not None else coords.min(dim=0)[0]\n",
    "        max_coord = torch.tensor([max_xyz[1], max_xyz[2]]) if max_xyz is not None else coords.max(dim=0)[0]\n",
    "    else:\n",
    "        raise ValueError(\"axis must be 'x', 'y', or 'z'\")\n",
    "\n",
    "    # Normalize to [0, 1] \n",
    "    coords_normalized = (coords - min_coord) / (max_coord - min_coord + 1e-6)\n",
    "    norm_depth = (depth - depth.min()) / (depth.max() - depth.min() + 1e-6)\n",
    "    if highest_first:\n",
    "        norm_depth = 1.0 - norm_depth\n",
    "    \n",
    "    # Scale to mask dimensions and round to integer indices\n",
    "    u = (coords_normalized[:, 0] * (W - 1)).long()\n",
    "    v = (coords_normalized[:, 1] * (H - 1)).long()\n",
    "    \n",
    "    # --- Step 3: Filter points using the mask ---\n",
    "    # Raster_filtered use sorted, \n",
    "    valid_within_bounds = (0 <= u) & (u < W) & (0 <= v) & (v < H)\n",
    "    if mask_2d is None:\n",
    "        valid_within_bounds_n_mask = valid_within_bounds.nonzero().squeeze(1)\n",
    "    else:\n",
    "        valid_within_bounds_n_mask = torch.zeros_like(u, dtype=torch.bool)\n",
    "        valid_within_bounds_n_mask[valid_within_bounds.nonzero().squeeze(1)] = mask_2d[v[valid_within_bounds],u[valid_within_bounds]]\n",
    "        valid_within_bounds_n_mask = valid_within_bounds_n_mask.nonzero().squeeze(1)\n",
    "    \n",
    "    filtered_pointcloud = pointcloud[valid_within_bounds_n_mask]\n",
    "    # Apply depth weighting if enabled\n",
    "    if depth_weighting:\n",
    "        cmap = plt.get_cmap('gist_rainbow')\n",
    "        raster_image = torch.zeros((H, W, 3), dtype=dtype, device=device)\n",
    "        raster_filtered_img = torch.zeros((H, W, 3), dtype=dtype, device=device)\n",
    "        \n",
    "        \n",
    "        # --- Filter points within bounds ---\n",
    "        u_valid, v_valid = u[valid_within_bounds], v[valid_within_bounds]\n",
    "        norm_depth_valid = norm_depth[valid_within_bounds]\n",
    "        \n",
    "        # --- Filter points within bounds and 2dMask ---\n",
    "        u_valid_mask, v_valid_mask = u[valid_within_bounds_n_mask], v[valid_within_bounds_n_mask]\n",
    "        norm_depth_valid_mask = norm_depth[valid_within_bounds_n_mask]\n",
    "        \n",
    "        # --- Vectorized occlusion handling within bounds---\n",
    "        pixel_keys = v_valid * W + u_valid\n",
    "        # Sort by highest first\n",
    "        sort_order = torch_lexsort(torch.stack([pixel_keys, -norm_depth_valid]))\n",
    "        u_valid, v_valid = u_valid[sort_order], v_valid[sort_order]\n",
    "        norm_depth_valid = norm_depth_valid[sort_order]\n",
    "        # Find the first occurence of each pixel        \n",
    "        unique_indices = torch.unique(v_valid * W + u_valid, return_inverse=False, return_counts=False)\n",
    "        u_valid, v_valid = u_valid[unique_indices], v_valid[unique_indices]\n",
    "        raster_image[v_valid, u_valid] = torch.tensor(\n",
    "                cmap(norm_depth_valid[unique_indices].detach().cpu().numpy())[:, :3], dtype=dtype, device=device\n",
    "            )\n",
    "        \n",
    "        # --- Vectorized occlusion handling within bounds and mask---\n",
    "        if mask_2d is None:\n",
    "            raster_filtered_img = raster_image.copy()\n",
    "        else:\n",
    "            pixel_keys = v_valid_mask * W + u_valid_mask\n",
    "            # Sort by highest first\n",
    "            sort_order = torch_lexsort(torch.stack([pixel_keys, -norm_depth_valid_mask]))\n",
    "            u_valid_mask, v_valid_mask = u_valid_mask[sort_order], v_valid_mask[sort_order]\n",
    "            norm_depth_valid_mask = norm_depth_valid_mask[sort_order]\n",
    "            # Find the first occurence of each pixel\n",
    "            unique_indices = torch.unique(v_valid_mask * W + u_valid_mask, return_inverse=False, return_counts=False, dim=0)\n",
    "            u_valid_mask, v_valid_mask = u_valid_mask[unique_indices], v_valid_mask[unique_indices]\n",
    "            raster_filtered_img[v_valid_mask, u_valid_mask] = torch.tensor(\n",
    "                cmap(norm_depth_valid_mask[unique_indices].detach().cpu().numpy())[:, :3], dtype=dtype, device=device\n",
    "            )\n",
    "    else:\n",
    "        # Binary version (original behavior)\n",
    "        raster_image = torch.zeros((H, W), dtype=torch.bool, device=device)\n",
    "        raster_filtered_img = torch.zeros((H, W), dtype=torch.bool, device=device)\n",
    "        raster_image[v[valid_within_bounds], u[valid_within_bounds]] = True\n",
    "        if mask_2d is None:\n",
    "            raster_filtered_img = raster_image.copy()\n",
    "        else:\n",
    "            raster_filtered_img[v[valid_within_bounds_n_mask], u[valid_within_bounds_n_mask]] = True\n",
    "    \n",
    "    \n",
    "    return filtered_pointcloud, raster_image, raster_filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 104489 is out of bounds for dimension 0 with size 26138",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 44\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# plt.imshow(raster_img, cmap=\"gray\")\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# plt.imshow(raster_img_filtered*255, cmap=\"gray\")\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n\u001b[1;32m     35\u001b[0m filtered_pc_highest, raster_img, raster_img_filtered \u001b[38;5;241m=\u001b[39m rasterize_3dto2D(\n\u001b[1;32m     36\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(pcd\u001b[38;5;241m.\u001b[39mpoints)), \n\u001b[1;32m     37\u001b[0m     mask_2d, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     depth_weighting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     42\u001b[0m )\n\u001b[0;32m---> 44\u001b[0m filtered_pc_highest, raster_img, raster_img_filtered \u001b[38;5;241m=\u001b[39m \u001b[43mrasterize_3dto2D_torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpcd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhighest_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth_weighting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(raster_img)\n\u001b[1;32m     53\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[11], line 199\u001b[0m, in \u001b[0;36mrasterize_3dto2D_torch\u001b[0;34m(pointcloud, mask_2d, img_shape, min_xyz, max_xyz, axis, highest_first, depth_weighting)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# Find the first occurence of each pixel        \u001b[39;00m\n\u001b[1;32m    198\u001b[0m unique_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munique(v_valid_mask \u001b[38;5;241m*\u001b[39m W \u001b[38;5;241m+\u001b[39m u_valid_mask, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 199\u001b[0m u_valid, v_valid \u001b[38;5;241m=\u001b[39m \u001b[43mu_valid\u001b[49m\u001b[43m[\u001b[49m\u001b[43munique_indices\u001b[49m\u001b[43m]\u001b[49m, v_valid[unique_indices]\n\u001b[1;32m    200\u001b[0m raster_image[v_valid, u_valid] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    201\u001b[0m         cmap(norm_depth_valid[unique_indices]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())[:, :\u001b[38;5;241m3\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m    202\u001b[0m     )\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# --- Vectorized occlusion handling within bounds and mask---\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 104489 is out of bounds for dimension 0 with size 26138"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from raster_pcd2img import rasterize_3dto2D, rasterize_3dto2D_numpy\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate a sample point cloud (N, 3)\n",
    "    pointcloud = np.random.rand(1000, 3) * 10\n",
    "    \n",
    "    # Create a dummy mask (H, W) (e.g., circle mask)\n",
    "    H, W = 480, 480\n",
    "    y, x = np.ogrid[:H, :W]\n",
    "    center = (W//2, H//2)\n",
    "    radius = 150\n",
    "    mask_2d = (x - center[0])**2 + (y - center[1])**2 <= radius**2\n",
    "    min_pts = np.array(pcd.points).min(axis=0) \n",
    "    max_pts = np.array(pcd.points).max(axis=0) \n",
    "    # Case 1: Highest-first (farthest points prioritized)\n",
    "    filtered_pc_highest, raster_img, raster_img_filtered = rasterize_3dto2D(\n",
    "        np.array(pcd.points), \n",
    "        mask_2d, \n",
    "        img_shape=(H,W),\n",
    "        axis='z',\n",
    "        min_xyz=min_pts,\n",
    "        max_xyz=max_pts,\n",
    "        highest_first=False,\n",
    "        depth_weighting=True\n",
    "    )\n",
    "    # plt.imshow(raster_img, cmap=\"gray\")\n",
    "    # plt.show()\n",
    "    # plt.imshow(raster_img_filtered*255, cmap=\"gray\")\n",
    "    # plt.show()\n",
    "    \n",
    "    filtered_pc_highest, raster_img, raster_img_filtered = rasterize_3dto2D(\n",
    "        torch.tensor(np.array(pcd.points)), \n",
    "        mask_2d, \n",
    "        #img_shape=(H,W),\n",
    "        axis='y',\n",
    "        highest_first=False,\n",
    "        depth_weighting=True\n",
    "    )\n",
    "    \n",
    "    filtered_pc_highest, raster_img, raster_img_filtered = rasterize_3dto2D_torch(\n",
    "        torch.tensor(np.array(pcd.points)), \n",
    "        mask_2d, \n",
    "        img_shape=(H,W),\n",
    "        axis='z',\n",
    "        highest_first=True,\n",
    "        depth_weighting=True,\n",
    "    )\n",
    "    plt.imshow(raster_img)\n",
    "    plt.show()\n",
    "    plt.imshow(raster_img_filtered)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    # Visualize\n",
    "    pcd_original = o3d.geometry.PointCloud()\n",
    "    pcd_original.points = o3d.utility.Vector3dVector(pointcloud)\n",
    "    pcd_original.paint_uniform_color([0.5, 0.5, 0.5])  # Gray\n",
    "    \n",
    "    pcd_highest = o3d.geometry.PointCloud()\n",
    "    pcd_highest.points = o3d.utility.Vector3dVector(filtered_pc_highest)\n",
    "    pcd_highest.paint_uniform_color([1, 0, 0])  # Red (farthest kept)\n",
    "    \n",
    "    \n",
    "    o3d.visualization.draw_geometries([pcd, pcd_highest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 5, 7, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "x_mask = np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1], dtype=bool)\n",
    "x[np.array([4,5])]\n",
    "x[x_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.0\n"
     ]
    }
   ],
   "source": [
    "x=0.02\n",
    "print((1-x)/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
